{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a26fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb3f586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Assign_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_size,hidden1_size,hidden2_size,out_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_l = nn.Linear(in_size,hidden1_size)\n",
    "        \n",
    "        self.hidden1_l = nn.Linear(hidden1_size,hidden2_size)\n",
    "        \n",
    "        self.hidden2_l = nn.Linear(hidden2_size,out_size)\n",
    "        \n",
    "    def forward(self,features):\n",
    "        \n",
    "        out_i = self.input_l( features )\n",
    "        \n",
    "        act_h1 = torch.tanh( out_i )\n",
    "        \n",
    "        out_h1 = self.hidden1_l( act_h1 )\n",
    "        \n",
    "        act_h2 = torch.tanh( out_h1 )\n",
    "        \n",
    "        Final_out = self.hidden2_l( act_h2 )\n",
    "        \n",
    "        return Final_out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ccc1fa",
   "metadata": {},
   "source": [
    "# Task 1: Function Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c1b056",
   "metadata": {},
   "source": [
    "### Extracting data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0d1568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537\n",
      "76\n",
      "155\n"
     ]
    }
   ],
   "source": [
    "inputs = np.genfromtxt('Data/task1/energy-data.txt',delimiter = '\\t')\n",
    "np.random.shuffle(inputs)\n",
    "\n",
    "train, rem = np.split( inputs, [int(0.7 * len(inputs))] , axis = 0)\n",
    "\n",
    "val , test   = np.split( rem , [int(0.33333 * len(rem))] , axis = 0)\n",
    "\n",
    "print(len(train))\n",
    "print(len(val))\n",
    "print(len(test))\n",
    "\n",
    "train = torch.from_numpy(train).float()\n",
    "test  = torch.from_numpy(test).float()\n",
    "val   = torch.from_numpy(val).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a628d4",
   "metadata": {},
   "source": [
    "### Function Approximation model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80d5b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Approx_model = Assign_Model(8,500,500,2)\n",
    "\n",
    "Delta_w = []\n",
    "for param in Approx_model.parameters():\n",
    "    Delta_w.append(torch.zeros(param.size()))\n",
    "    \n",
    "    \n",
    "loss_fn = F.mse_loss\n",
    "\n",
    "\n",
    "lr = 1e-6\n",
    "\n",
    "al = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96af6377",
   "metadata": {},
   "source": [
    "### Training Phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "629fe00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Total_Loss: 8316.3063, Average_Loss: 15.4866\n",
      "Epoch [20/1000], Total_Loss: 8270.2826, Average_Loss: 15.4009\n",
      "Epoch [30/1000], Total_Loss: 8243.8255, Average_Loss: 15.3516\n",
      "Epoch [40/1000], Total_Loss: 8240.9408, Average_Loss: 15.3463\n",
      "Epoch [50/1000], Total_Loss: 8217.1718, Average_Loss: 15.3020\n",
      "Epoch [60/1000], Total_Loss: 8195.8279, Average_Loss: 15.2622\n",
      "Epoch [70/1000], Total_Loss: 8178.8287, Average_Loss: 15.2306\n",
      "Epoch [80/1000], Total_Loss: 8166.5569, Average_Loss: 15.2077\n",
      "Epoch [90/1000], Total_Loss: 8130.3274, Average_Loss: 15.1403\n",
      "Epoch [100/1000], Total_Loss: 8086.6897, Average_Loss: 15.0590\n",
      "Epoch [110/1000], Total_Loss: 8050.0878, Average_Loss: 14.9909\n",
      "Epoch [120/1000], Total_Loss: 8026.5939, Average_Loss: 14.9471\n",
      "Epoch [130/1000], Total_Loss: 8004.5983, Average_Loss: 14.9061\n",
      "Epoch [140/1000], Total_Loss: 7975.3637, Average_Loss: 14.8517\n",
      "Epoch [150/1000], Total_Loss: 7947.5570, Average_Loss: 14.7999\n",
      "Epoch [160/1000], Total_Loss: 7913.8971, Average_Loss: 14.7372\n",
      "Epoch [170/1000], Total_Loss: 7892.9790, Average_Loss: 14.6983\n",
      "Epoch [180/1000], Total_Loss: 7859.2612, Average_Loss: 14.6355\n",
      "Epoch [190/1000], Total_Loss: 7824.9241, Average_Loss: 14.5716\n",
      "Epoch [200/1000], Total_Loss: 7791.7125, Average_Loss: 14.5097\n",
      "Epoch [210/1000], Total_Loss: 7759.7939, Average_Loss: 14.4503\n",
      "Epoch [220/1000], Total_Loss: 7727.1993, Average_Loss: 14.3896\n",
      "Epoch [230/1000], Total_Loss: 7703.6084, Average_Loss: 14.3456\n",
      "Epoch [240/1000], Total_Loss: 7665.9534, Average_Loss: 14.2755\n",
      "Epoch [250/1000], Total_Loss: 7630.4753, Average_Loss: 14.2095\n",
      "Epoch [260/1000], Total_Loss: 7584.2697, Average_Loss: 14.1234\n",
      "Epoch [270/1000], Total_Loss: 7543.2305, Average_Loss: 14.0470\n",
      "Epoch [280/1000], Total_Loss: 7505.6554, Average_Loss: 13.9770\n",
      "Epoch [290/1000], Total_Loss: 7466.9294, Average_Loss: 13.9049\n",
      "Epoch [300/1000], Total_Loss: 7421.5598, Average_Loss: 13.8204\n",
      "Epoch [310/1000], Total_Loss: 7383.4937, Average_Loss: 13.7495\n",
      "Epoch [320/1000], Total_Loss: 7332.6195, Average_Loss: 13.6548\n",
      "Epoch [330/1000], Total_Loss: 7290.3653, Average_Loss: 13.5761\n",
      "Epoch [340/1000], Total_Loss: 7234.1312, Average_Loss: 13.4714\n",
      "Epoch [350/1000], Total_Loss: 7189.0308, Average_Loss: 13.3874\n",
      "Epoch [360/1000], Total_Loss: 7150.1978, Average_Loss: 13.3151\n",
      "Epoch [370/1000], Total_Loss: 7122.7803, Average_Loss: 13.2640\n",
      "Epoch [380/1000], Total_Loss: 7064.2936, Average_Loss: 13.1551\n",
      "Epoch [390/1000], Total_Loss: 7019.4486, Average_Loss: 13.0716\n",
      "Epoch [400/1000], Total_Loss: 6976.6491, Average_Loss: 12.9919\n",
      "Epoch [410/1000], Total_Loss: 6937.3665, Average_Loss: 12.9187\n",
      "Epoch [420/1000], Total_Loss: 6900.2454, Average_Loss: 12.8496\n",
      "Epoch [430/1000], Total_Loss: 6862.7257, Average_Loss: 12.7797\n",
      "Epoch [440/1000], Total_Loss: 6815.3554, Average_Loss: 12.6915\n",
      "Epoch [450/1000], Total_Loss: 6808.2681, Average_Loss: 12.6783\n",
      "Epoch [460/1000], Total_Loss: 6769.1142, Average_Loss: 12.6054\n",
      "Epoch [470/1000], Total_Loss: 6731.2319, Average_Loss: 12.5349\n",
      "Epoch [480/1000], Total_Loss: 6696.0373, Average_Loss: 12.4693\n",
      "Epoch [490/1000], Total_Loss: 6656.7648, Average_Loss: 12.3962\n",
      "Epoch [500/1000], Total_Loss: 6590.6176, Average_Loss: 12.2730\n",
      "Epoch [510/1000], Total_Loss: 6558.6339, Average_Loss: 12.2135\n",
      "Epoch [520/1000], Total_Loss: 6522.9134, Average_Loss: 12.1470\n",
      "Epoch [530/1000], Total_Loss: 6484.1256, Average_Loss: 12.0747\n",
      "Epoch [540/1000], Total_Loss: 6447.9896, Average_Loss: 12.0074\n",
      "Epoch [550/1000], Total_Loss: 6411.9213, Average_Loss: 11.9403\n",
      "Epoch [560/1000], Total_Loss: 6376.1961, Average_Loss: 11.8737\n",
      "Epoch [570/1000], Total_Loss: 6344.8985, Average_Loss: 11.8155\n",
      "Epoch [580/1000], Total_Loss: 6320.0716, Average_Loss: 11.7692\n",
      "Epoch [590/1000], Total_Loss: 6270.3107, Average_Loss: 11.6766\n",
      "Epoch [600/1000], Total_Loss: 6238.4003, Average_Loss: 11.6171\n",
      "Epoch [610/1000], Total_Loss: 6217.4699, Average_Loss: 11.5782\n",
      "Epoch [620/1000], Total_Loss: 6190.7704, Average_Loss: 11.5284\n",
      "Epoch [630/1000], Total_Loss: 6159.8162, Average_Loss: 11.4708\n",
      "Epoch [640/1000], Total_Loss: 6198.9137, Average_Loss: 11.5436\n",
      "Epoch [650/1000], Total_Loss: 6334.4452, Average_Loss: 11.7960\n",
      "Epoch [660/1000], Total_Loss: 7154.3495, Average_Loss: 13.3228\n",
      "Epoch [670/1000], Total_Loss: 7102.5473, Average_Loss: 13.2263\n",
      "Epoch [680/1000], Total_Loss: 7064.1612, Average_Loss: 13.1549\n",
      "Epoch [690/1000], Total_Loss: 7026.5065, Average_Loss: 13.0847\n",
      "Epoch [700/1000], Total_Loss: 6989.1655, Average_Loss: 13.0152\n",
      "Epoch [710/1000], Total_Loss: 6954.5822, Average_Loss: 12.9508\n",
      "Epoch [720/1000], Total_Loss: 6912.6999, Average_Loss: 12.8728\n",
      "Epoch [730/1000], Total_Loss: 6874.2062, Average_Loss: 12.8011\n",
      "Epoch [740/1000], Total_Loss: 6839.5667, Average_Loss: 12.7366\n",
      "Epoch [750/1000], Total_Loss: 6808.5838, Average_Loss: 12.6789\n",
      "Epoch [760/1000], Total_Loss: 6753.4770, Average_Loss: 12.5763\n",
      "Epoch [770/1000], Total_Loss: 6724.2718, Average_Loss: 12.5219\n",
      "Epoch [780/1000], Total_Loss: 6694.7239, Average_Loss: 12.4669\n",
      "Epoch [790/1000], Total_Loss: 6646.1049, Average_Loss: 12.3764\n",
      "Epoch [800/1000], Total_Loss: 6608.2930, Average_Loss: 12.3059\n",
      "Epoch [810/1000], Total_Loss: 6507.8217, Average_Loss: 12.1188\n",
      "Epoch [820/1000], Total_Loss: 6456.9012, Average_Loss: 12.0240\n",
      "Epoch [830/1000], Total_Loss: 6407.4757, Average_Loss: 11.9320\n",
      "Epoch [840/1000], Total_Loss: 6357.3967, Average_Loss: 11.8387\n",
      "Epoch [850/1000], Total_Loss: 6312.5418, Average_Loss: 11.7552\n",
      "Epoch [860/1000], Total_Loss: 6267.3702, Average_Loss: 11.6711\n",
      "Epoch [870/1000], Total_Loss: 6235.5127, Average_Loss: 11.6118\n",
      "Epoch [880/1000], Total_Loss: 6229.6164, Average_Loss: 11.6008\n",
      "Epoch [890/1000], Total_Loss: 6175.7446, Average_Loss: 11.5005\n",
      "Epoch [900/1000], Total_Loss: 6153.5085, Average_Loss: 11.4590\n",
      "Epoch [910/1000], Total_Loss: 6133.4547, Average_Loss: 11.4217\n",
      "Epoch [920/1000], Total_Loss: 6091.9582, Average_Loss: 11.3444\n",
      "Epoch [930/1000], Total_Loss: 6023.5140, Average_Loss: 11.2170\n",
      "Epoch [940/1000], Total_Loss: 6144.5545, Average_Loss: 11.4424\n",
      "Epoch [950/1000], Total_Loss: 6008.3656, Average_Loss: 11.1888\n",
      "Epoch [960/1000], Total_Loss: 5942.0362, Average_Loss: 11.0652\n",
      "Epoch [970/1000], Total_Loss: 5904.9976, Average_Loss: 10.9963\n",
      "Epoch [980/1000], Total_Loss: 5876.4191, Average_Loss: 10.9431\n",
      "Epoch [990/1000], Total_Loss: 5858.1787, Average_Loss: 10.9091\n",
      "Epoch [1000/1000], Total_Loss: 5830.4011, Average_Loss: 10.8574\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    Total_loss = 0\n",
    "    for X in train:\n",
    "        preds = Approx_model(X[:8])\n",
    "        \n",
    "        loss = loss_fn(preds,X[8:])\n",
    "        \n",
    "        Total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            i = 0\n",
    "            for param in Approx_model.parameters():\n",
    "                \n",
    "                Delta_w[i] =  - (lr*param.grad) + (al*Delta_w[i])\n",
    "                \n",
    "                param += (Delta_w[i])\n",
    "                \n",
    "                param.grad.zero_()\n",
    "                \n",
    "                i += 1\n",
    "        \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('Epoch [{}/{}], Total_Loss: {:.4f}, Average_Loss: {:.4f}'.format(epoch+1,num_epochs, Total_loss,Total_loss/len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab3b6287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.6807, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2585, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.5278, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.4906, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.3623, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.8964, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1174, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9660, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2471, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7986, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.8442, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.9075, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6659, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6217, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "tensor(17.0631, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6756, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.8903, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.9443, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.7426, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.0905, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.8724, grad_fn=<MseLossBackward0>)\n",
      "tensor(55.8773, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.4529, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1280, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7965, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.2322, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0401, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2714, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.8715, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1177, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.2112, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1142, grad_fn=<MseLossBackward0>)\n",
      "tensor(18.9852, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1008, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.1077, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.0301, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4220, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4474, grad_fn=<MseLossBackward0>)\n",
      "tensor(57.8477, grad_fn=<MseLossBackward0>)\n",
      "tensor(18.2287, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5010, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7506, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.2164, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4351, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3478, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0496, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7126, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.2248, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7226, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.3611, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.9026, grad_fn=<MseLossBackward0>)\n",
      "tensor(81.5263, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.7463, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.9781, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6125, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.5857, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.8311, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6979, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0993, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.7990, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.6568, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.4200, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.5475, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5412, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1622, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7352, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0558, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.8965, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1679, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.2369, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0754, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0699, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.4273, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.3729, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0515, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0482, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.4020, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2287, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2579, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9526, grad_fn=<MseLossBackward0>)\n",
      "tensor(16.7227, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.5106, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.8442, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5823, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.8885, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.9098, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3073, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.1583, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.6110, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1935, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4138, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.1278, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4409, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.1431, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6320, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.9825, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7281, grad_fn=<MseLossBackward0>)\n",
      "tensor(18.2647, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9966, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4707, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2483, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6385, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7188, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.4711, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.2839, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.0672, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7987, grad_fn=<MseLossBackward0>)\n",
      "tensor(13.6027, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1337, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.6991, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3126, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2676, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7519, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6896, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3451, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.9591, grad_fn=<MseLossBackward0>)\n",
      "tensor(17.8071, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.8793, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.7325, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4560, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7390, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.2528, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.8142, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2033, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.8919, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.9519, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.8951, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.2486, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.5425, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9539, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1644, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7816, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.3035, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.8610, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1827, grad_fn=<MseLossBackward0>)\n",
      "tensor(13.1009, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6403, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0969, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4115, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4864, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3507, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.0815, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9396, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "tensor(15.8335, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.7718, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.6413, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7159, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5398, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.8244, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1643, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4891, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7007, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.3275, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4531, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5104, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5176, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7641, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1312, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.4201, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.8093, grad_fn=<MseLossBackward0>)\n",
      "tensor(14.4001, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4417, grad_fn=<MseLossBackward0>)\n",
      "tensor(16.3823, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.8003, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.9113, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.3211, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4552, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7585, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5449, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2445, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4745, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.8511, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.6295, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.1146, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9025, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5232, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1603, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.8465, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3598, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6962, grad_fn=<MseLossBackward0>)\n",
      "tensor(18.8495, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.0867, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4776, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4097, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7887, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0522, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4277, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1897, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9083, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3947, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4898, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.7636, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6741, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4298, grad_fn=<MseLossBackward0>)\n",
      "tensor(12.0087, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4047, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.2190, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4517, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.8475, grad_fn=<MseLossBackward0>)\n",
      "tensor(59.3933, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0665, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4459, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.1309, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.1491, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.2342, grad_fn=<MseLossBackward0>)\n",
      "tensor(62.6888, grad_fn=<MseLossBackward0>)\n",
      "tensor(161.7602, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.8252, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.1673, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.4291, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5056, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5646, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.6504, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7778, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2891, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6786, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6946, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1985, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4626, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.3511, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.1064, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6745, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6662, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9647, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.5739, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.1437, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1368, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.1526, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0560, grad_fn=<MseLossBackward0>)\n",
      "tensor(12.7884, grad_fn=<MseLossBackward0>)\n",
      "tensor(68.2474, grad_fn=<MseLossBackward0>)\n",
      "tensor(12.9920, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0561, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.6894, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.1553, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0882, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2761, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3288, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.7452, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7889, grad_fn=<MseLossBackward0>)\n",
      "tensor(58.4825, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.1588, grad_fn=<MseLossBackward0>)\n",
      "tensor(18.4170, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.6246, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1554, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.9739, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.3168, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.3640, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7254, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.4772, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.2276, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.7134, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.3211, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6020, grad_fn=<MseLossBackward0>)\n",
      "tensor(161.9024, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5789, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.4850, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4628, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.9775e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.8582, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6159, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2758, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6251, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.0339, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.9528, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.7898, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8727, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.1666, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1855, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5390, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5061, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3321, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.4736, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.7375, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.1769, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7780, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2982, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9734, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.2251, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2706, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4343, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4808, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5530, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.3531, grad_fn=<MseLossBackward0>)\n",
      "tensor(49.1628, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.5857, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6599, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4441, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3816, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.0693, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1239, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(13.0048, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.3355, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6657, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6535, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.8783, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0594, grad_fn=<MseLossBackward0>)\n",
      "tensor(94.0855, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0915, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6716, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8477, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.5974, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.4666, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7789, grad_fn=<MseLossBackward0>)\n",
      "tensor(70.3199, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.6991, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3782, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.3285, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.2404, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4282, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3604, grad_fn=<MseLossBackward0>)\n",
      "tensor(53.8136, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2920, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.6168, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.7488, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.9786, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.0844, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5937, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6693, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1723, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6041, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.0942, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.7689, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1337, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0536, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5542, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.8651, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5618, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.4343, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7737, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9008, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.8207, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6416, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.8920, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.7485, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.7992, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.5450, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1859, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8962, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6079, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1338, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.8486, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.8356, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3861, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.7540, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.0217, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2229, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3749, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3828, grad_fn=<MseLossBackward0>)\n",
      "tensor(18.3224, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.9096, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4133, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0377, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2049, grad_fn=<MseLossBackward0>)\n",
      "tensor(17.9810, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.9711, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7336, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3102, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.7571, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3930, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6808, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.8817, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.6234, grad_fn=<MseLossBackward0>)\n",
      "tensor(16.1488, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4403, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.2519, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.3897, grad_fn=<MseLossBackward0>)\n",
      "tensor(161.8043, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.0289, grad_fn=<MseLossBackward0>)\n",
      "tensor(17.8415, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0616, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.2619, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8916, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.7120, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.8508, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.8566, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.4681, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4170, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0125, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1186, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.3742, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0826, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.5048, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6705, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.8362, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.7522, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0676, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.6027, grad_fn=<MseLossBackward0>)\n",
      "tensor(17.2284, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4922, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0587, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4917, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4339, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7410, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.4026, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1364, grad_fn=<MseLossBackward0>)\n",
      "tensor(57.1065, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.6492, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9039, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.2720, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.0137, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6143, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.5610, grad_fn=<MseLossBackward0>)\n",
      "tensor(13.7023, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9738, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1576, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4609, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.9279, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.5687, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.3096, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2809, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.7276, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.3670, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.3099, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9280, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.6047, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.6014, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6017, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2117, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4770, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.2686, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1346, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6368, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4012, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1253, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3484, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.1149, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3383, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3925, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0469, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5521, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4438, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0762, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9629, grad_fn=<MseLossBackward0>)\n",
      "tensor(15.8983, grad_fn=<MseLossBackward0>)\n",
      "tensor(72.3048, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6647, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.9385, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3662, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3179, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2345, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3780, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.7193, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0739, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3313, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3946, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3922, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2688, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.7095, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6634, grad_fn=<MseLossBackward0>)\n",
      "tensor(12.8251, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0691, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0159, grad_fn=<MseLossBackward0>)\n",
      "tensor(14.6161, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.1417, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9738, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.1914, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1098, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1094, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2108, grad_fn=<MseLossBackward0>)\n",
      "tensor(13.0870, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9064, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.3742, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4084, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9650, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6038, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.4979, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5192, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6194, grad_fn=<MseLossBackward0>)\n",
      "tensor(16.0728, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4512, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.4311, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0022, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1422, grad_fn=<MseLossBackward0>)\n",
      "tensor(80.1259, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.9355, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2825, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.9927, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.9855, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4508, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5050, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0531, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1980, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2317, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9485, grad_fn=<MseLossBackward0>)\n",
      "tensor(12.3415, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.3221, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7237, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6164, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1616, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4381, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4660, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9629, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4488, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.8799, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6877, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.0922, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4022, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1192, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5811, grad_fn=<MseLossBackward0>)\n",
      "tensor(60.1059, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5564, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0853, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0569, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.8496, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7734, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.9067, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.5446, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1215, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6315, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.5586, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.7413, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7269, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1351, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6755, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.4175, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0060, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0107, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.691933568675838"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total_loss = 0\n",
    "for X in train:\n",
    "    preds = Approx_model(X[:8])\n",
    "\n",
    "    loss = loss_fn(preds,X[8:])\n",
    "    print(loss)\n",
    "    Total_loss += loss.item()\n",
    "Total_loss/537"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8ab66c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(28.4115, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7647, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.9598, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7379, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4002, grad_fn=<MseLossBackward0>)\n",
      "tensor(16.5830, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2240, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4537, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.8452, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.9297, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.9357, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.4231, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4227, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2916, grad_fn=<MseLossBackward0>)\n",
      "tensor(17.6013, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7829, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4097, grad_fn=<MseLossBackward0>)\n",
      "tensor(81.9411, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.0317, grad_fn=<MseLossBackward0>)\n",
      "tensor(85.5892, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3102, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1220, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0624, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.1828, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.3903, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.8835, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.7189, grad_fn=<MseLossBackward0>)\n",
      "tensor(17.2859, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.1443, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.8495, grad_fn=<MseLossBackward0>)\n",
      "tensor(13.3174, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.9097, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.5095, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.3847, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.9364, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.6665, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.6893, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0587, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3072, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7975, grad_fn=<MseLossBackward0>)\n",
      "tensor(13.4801, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3285, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.4250, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.8829, grad_fn=<MseLossBackward0>)\n",
      "tensor(92.0266, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4940, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.5401, grad_fn=<MseLossBackward0>)\n",
      "tensor(93.6904, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1303, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8491, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.6569, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6805, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1993, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1835, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.8866, grad_fn=<MseLossBackward0>)\n",
      "tensor(50.6542, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7319, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.1370, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6403, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0968, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1412, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.8310, grad_fn=<MseLossBackward0>)\n",
      "tensor(15.9551, grad_fn=<MseLossBackward0>)\n",
      "tensor(16.2077, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9694, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0321, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.2978, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2278, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.7243, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0568, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4415, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.5245, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.1563, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14.42916648425652"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total_loss = 0\n",
    "for X in val:\n",
    "    preds = Approx_model(X[:8])\n",
    "\n",
    "    loss = loss_fn(preds,X[8:])\n",
    "    print(loss)\n",
    "    Total_loss += loss.item()\n",
    "Total_loss/len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4850f7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.3663, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1254, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.9722, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1731, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.3626, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1725, grad_fn=<MseLossBackward0>)\n",
      "tensor(101.2972, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0314, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1994, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.0746, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.7593, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0619, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.8542, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.1375, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4899, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.2595, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0911, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.1771, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2257, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.5474, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.7061, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3055, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.1818, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.7366, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.8451, grad_fn=<MseLossBackward0>)\n",
      "tensor(161.7761, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.0201, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2820, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.2007, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9132, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3923, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.8529, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2895, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3990, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7945, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3397, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.8040, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0605, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.5763, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5269, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.9581, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4147, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3811, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.1356, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.9440, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.9526, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.1387, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.3971, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4715, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4197, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.4222, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7824, grad_fn=<MseLossBackward0>)\n",
      "tensor(18.9566, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0985, grad_fn=<MseLossBackward0>)\n",
      "tensor(19.5196, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.1522, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4666, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2309, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1552, grad_fn=<MseLossBackward0>)\n",
      "tensor(17.5889, grad_fn=<MseLossBackward0>)\n",
      "tensor(50.8237, grad_fn=<MseLossBackward0>)\n",
      "tensor(13.8516, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4993, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2618, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9038, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0090, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.1997, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5527, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.8765, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.9289, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.8252, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.4517, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.6010, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.9635, grad_fn=<MseLossBackward0>)\n",
      "tensor(65.6144, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3694, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8208, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.2071, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.8214, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.0212, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6293, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.1814, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.7078, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2155, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6062, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.5210, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6136, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1144, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3794, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2964, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.2367, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4717, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5915, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.0371, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.2756, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3550, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.1122, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7701, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7660, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.3108, grad_fn=<MseLossBackward0>)\n",
      "tensor(81.8171, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1791, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.2342, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1092, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4727, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.6812, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4348, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.5492, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.6002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0667, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4810, grad_fn=<MseLossBackward0>)\n",
      "tensor(14.1403, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.5737, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5770, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0811, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1516, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0927, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0384, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6727, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.7729, grad_fn=<MseLossBackward0>)\n",
      "tensor(13.7655, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.2692, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2802, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.9498, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.2770, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.6480, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.6185, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1426, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9708, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.9135, grad_fn=<MseLossBackward0>)\n",
      "tensor(16.3367, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6914, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4902, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.3576, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.8012, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5761, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.1711, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.3669, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4775, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6177, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.7354, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.8129, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3273, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5733, grad_fn=<MseLossBackward0>)\n",
      "tensor(13.9655, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.1016, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.4316, grad_fn=<MseLossBackward0>)\n",
      "tensor(50.2193, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4114, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.0073, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.1763, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0215, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.08471355787929"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total_loss = 0\n",
    "for X in test:\n",
    "    preds = Approx_model(X[:8])\n",
    "\n",
    "    loss = loss_fn(preds,X[8:])\n",
    "    print(loss)\n",
    "    Total_loss += loss.item()\n",
    "Total_loss/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903405fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_test",
   "language": "python",
   "name": "dl_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
